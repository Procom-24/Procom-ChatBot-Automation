{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import langchain\n",
    "#import pypdf\n",
    "import sentence_transformers\n",
    "#import tiktoken\n",
    "import openai\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.document_loaders import Docx2txtLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceHubEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘Procom_Collection’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir Procom_Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "\n",
    "def read_docx_as_single_page(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    text = \"\"\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text += paragraph.text + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def read_pdf_as_single_page(pdf_path):\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        pdf_reader = PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            # Extract text from the current page and append it to the string\n",
    "            text += pdf_reader.pages[page_num].extract_text()\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = []\n",
    "for file in os.listdir(\"Procom_test\"):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdf_path = \"./Procom_test/\" + file\n",
    "        document.append(read_pdf_as_single_page(pdf_path))  # Append instead of extend\n",
    "    elif file.endswith(\".docx\") or file.endswith(\".doc\"):\n",
    "        doc_path = \"./Procom_test/\" + file\n",
    "        document.append(read_docx_as_single_page(doc_path))  # Append instead of extend\n",
    "    elif file.endswith(\".txt\"):\n",
    "        txt_path = \"./Procom_test/\" + file\n",
    "        loader = TextLoader(txt_path)\n",
    "        document.append(loader.load())  # Append instead of extend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(\"./Procom_KnowledgeBase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromadb.utils.embedding_functions as embedding_functions\n",
    "# openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "#             api_key=\"YOUR API KEY\",\n",
    "#             model_name=\"text-embedding-ada-002\"\n",
    "#             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chroma_client.get_or_create_collection(name = \"Procom_Competitions\", embedding_function = sentence_transformer_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(document):\n",
    "   client.add(documents = document[i], metadatas={\"source\": f\"Procom_Docs_{i + 1}\"}, ids=[str(i)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' AI Showdown \\n Overview \\n The  AI  Showdown  is  a  dynamic  competition  where  participants  delve  into  real-world  datasets, \\n applying  their  expertise  to  solve  intricate  problems.  The  challenge  tests  skills  in  data  cleaning, \\n exploratory  data  analysis,  insight  and  pattern  extraction,  and  predictive  modeling.  Participants \\n are  evaluated  based  on  solution  accuracy ,  model  effectiveness,  and  their  ability  to  communicate \\n insights.  The  competition  is  designed  to  cater  to  participants  of  all  levels,  whether  you  are  a \\n newbie,  a  beginner ,  or  a  seasoned  ML  expert.  The  event  not  only  offers  winners  valuable  prizes \\n but  also  recognition,  making  the  challenge  a  dynamic  platform  for  showcasing  and  advancing \\n data science and machine learning expertise. \\n Rounds \\n The competition consists of two rounds. \\n Round 1: Exploratory Data Analysis (EDA) and Modeling, T eams will be provided with a CSV \\n file and teams have to perform EDA which have a deadline of 1-2 hours and should be done \\n onsite. Next they have to apply ML models on that data, and have a deadline till 1 1:59 pm day 1. \\n Round 2: Modeling without Internet, Qualified teams will be provided with CSV but this time \\n data will be refined and ready to apply models. T eams will have to apply models based on their \\n knowledge and do it in 3 hours without internet access. \\n Team Formation \\n Each team can have a maximum of 3 members. \\n Rules \\n ●  Internet access will  be allowed throughout the competition  venue for round 1 only . \\n ●  Teams found using Chat GPT , Google Bard or any other websites (except during round 1) \\n will be  disqualified. \\n ●  Mobile usage is strictly  prohibited. \\n ●  Collaborating with other groups in any sort of way will lead to  disqualification. \\n ●  Equipment, other than provided, are  NOT  allowed during  the competition. \\n ●  Decision of the Judges will be final. \\n ●  Submissions will be taken using  Kaggle  . \\n ●  Edibles are  strictly pr ohibited  in the competition  venue \\n ●  Any team will  disqualify  due to any of the reasons  mentioned below \\n ○  Plagiarism  ○  Usage of internet during the competition (except during round 1) \\n ○  Disturbance or misconduct with any invigilator or fellow competitors \\n ●  Intentional data manipulation, fabrication, misrepresentation, or plagiarism will lead to \\n immediate  disqualification  . \\n ●  Unauthorized access to additional data sources or confidential information will result in \\n disqualification  . \\n ●  Teams are  requir ed  to bring the laptops (with required  software, i.e. Python, Jupyter \\n Notebook, and DS/ML libraries installed) with them in the competition and venue will be \\n communicated through the mail beforehand. \\n ●  Competition will be started on the stated time. All teams are expected to arrive on time or \\n earlier to get a head start on instructions. \\n ●  The or ganizers reserve the right to modify the rules or competition parameters in the \\n event of unforeseen challenges, technical dif ficulties, or circumstances beyond control. \\n Any changes will be communicated promptly to all participants to ensure fairness and \\n transparency . '"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = client.query(query_texts = \"What is AI showdown about\", n_results = 1)\n",
    "t['documents'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(contents, User_input, temperature=0):\n",
    "    messages =  [\n",
    "        {'role':'system', 'content':\"\"\"You are a chatbot of an event called 'PROCOM', and when ever you reply, you will write 'PROCOM BOT responded with: ' and then you will give the response.\n",
    "        if there is something question related in the provided data then give suitable response for the question that is relevant and the question that is not relevant, if you are unable to respond to the query, then kindly answer with irrelevant information asked. \n",
    "        \"\"\"},    \n",
    "        {'role':'user', 'content':contents},\n",
    "        {'role':'assistant', 'content':User_input}\n",
    "    ]                                 \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' AI Showdown \\n Overview \\n The  AI  Showdown  is  a  dynamic  competition  where  participants  delve  into  real-world  datasets, \\n applying  their  expertise  to  solve  intricate  problems.  The  challenge  tests  skills  in  data  cleaning, \\n exploratory  data  analysis,  insight  and  pattern  extraction,  and  predictive  modeling.  Participants \\n are  evaluated  based  on  solution  accuracy ,  model  effectiveness,  and  their  ability  to  communicate \\n insights.  The  competition  is  designed  to  cater  to  participants  of  all  levels,  whether  you  are  a \\n newbie,  a  beginner ,  or  a  seasoned  ML  expert.  The  event  not  only  offers  winners  valuable  prizes \\n but  also  recognition,  making  the  challenge  a  dynamic  platform  for  showcasing  and  advancing \\n data science and machine learning expertise. \\n Rounds \\n The competition consists of two rounds. \\n Round 1: Exploratory Data Analysis (EDA) and Modeling, T eams will be provided with a CSV \\n file and teams have to perform EDA which have a deadline of 1-2 hours and should be done \\n onsite. Next they have to apply ML models on that data, and have a deadline till 1 1:59 pm day 1. \\n Round 2: Modeling without Internet, Qualified teams will be provided with CSV but this time \\n data will be refined and ready to apply models. T eams will have to apply models based on their \\n knowledge and do it in 3 hours without internet access. \\n Team Formation \\n Each team can have a maximum of 3 members. \\n Rules \\n ●  Internet access will  be allowed throughout the competition  venue for round 1 only . \\n ●  Teams found using Chat GPT , Google Bard or any other websites (except during round 1) \\n will be  disqualified. \\n ●  Mobile usage is strictly  prohibited. \\n ●  Collaborating with other groups in any sort of way will lead to  disqualification. \\n ●  Equipment, other than provided, are  NOT  allowed during  the competition. \\n ●  Decision of the Judges will be final. \\n ●  Submissions will be taken using  Kaggle  . \\n ●  Edibles are  strictly pr ohibited  in the competition  venue \\n ●  Any team will  disqualify  due to any of the reasons  mentioned below \\n ○  Plagiarism  ○  Usage of internet during the competition (except during round 1) \\n ○  Disturbance or misconduct with any invigilator or fellow competitors \\n ●  Intentional data manipulation, fabrication, misrepresentation, or plagiarism will lead to \\n immediate  disqualification  . \\n ●  Unauthorized access to additional data sources or confidential information will result in \\n disqualification  . \\n ●  Teams are  requir ed  to bring the laptops (with required  software, i.e. Python, Jupyter \\n Notebook, and DS/ML libraries installed) with them in the competition and venue will be \\n communicated through the mail beforehand. \\n ●  Competition will be started on the stated time. All teams are expected to arrive on time or \\n earlier to get a head start on instructions. \\n ●  The or ganizers reserve the right to modify the rules or competition parameters in the \\n event of unforeseen challenges, technical dif ficulties, or circumstances beyond control. \\n Any changes will be communicated promptly to all participants to ensure fairness and \\n transparency . '"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = str(input(\"Enter a query: \"))\n",
    "content = client.query(query_texts = user_input, n_results = 1)\n",
    "content['documents'][0][0]\n",
    "#response = get_completion_from_messages(content['documents'][0], user_input, temperature = 0.7)\n",
    "#print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
